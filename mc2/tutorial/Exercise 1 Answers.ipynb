{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Party XGBoost on Data Subset\n",
    "First we'll train an XGBoost model on a subset of the data. This simulates the federated setting in that a party will only have a subset of the data that's available to the central trusted server for training. We'll look at the performance of a XGBoost model that's only trained on this subset. \n",
    "![title](img/exercise1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let `p` be your party ID. Load in and examine the training data partition belonging to your party, located at /data/training_data_<partition>.csv, to get a better understanding of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2007</td>\n",
       "      <td>25.23214</td>\n",
       "      <td>-232.77465</td>\n",
       "      <td>-37.51542</td>\n",
       "      <td>-40.34335</td>\n",
       "      <td>56.11564</td>\n",
       "      <td>-55.94831</td>\n",
       "      <td>43.06882</td>\n",
       "      <td>15.46278</td>\n",
       "      <td>-38.67370</td>\n",
       "      <td>...</td>\n",
       "      <td>-15.64058</td>\n",
       "      <td>257.69408</td>\n",
       "      <td>113.59740</td>\n",
       "      <td>-90.14988</td>\n",
       "      <td>-13.41911</td>\n",
       "      <td>-72.59105</td>\n",
       "      <td>-185.49959</td>\n",
       "      <td>1.16272</td>\n",
       "      <td>-73.13128</td>\n",
       "      <td>-6.89193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2007</td>\n",
       "      <td>27.96974</td>\n",
       "      <td>-166.08713</td>\n",
       "      <td>-11.19265</td>\n",
       "      <td>-28.07397</td>\n",
       "      <td>-56.10902</td>\n",
       "      <td>-35.47258</td>\n",
       "      <td>23.35854</td>\n",
       "      <td>7.19973</td>\n",
       "      <td>-36.81179</td>\n",
       "      <td>...</td>\n",
       "      <td>21.49227</td>\n",
       "      <td>289.05914</td>\n",
       "      <td>-34.75972</td>\n",
       "      <td>-19.38242</td>\n",
       "      <td>2.44006</td>\n",
       "      <td>-67.78591</td>\n",
       "      <td>-46.62749</td>\n",
       "      <td>0.38383</td>\n",
       "      <td>98.98315</td>\n",
       "      <td>13.14364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2007</td>\n",
       "      <td>24.75152</td>\n",
       "      <td>-97.45055</td>\n",
       "      <td>-40.15226</td>\n",
       "      <td>-43.39929</td>\n",
       "      <td>-57.25665</td>\n",
       "      <td>-33.93026</td>\n",
       "      <td>-1.95605</td>\n",
       "      <td>0.93121</td>\n",
       "      <td>7.76578</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.96584</td>\n",
       "      <td>573.94557</td>\n",
       "      <td>11.83355</td>\n",
       "      <td>-107.81947</td>\n",
       "      <td>-3.42495</td>\n",
       "      <td>-141.79299</td>\n",
       "      <td>-150.79400</td>\n",
       "      <td>0.55715</td>\n",
       "      <td>148.71490</td>\n",
       "      <td>-2.41587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2007</td>\n",
       "      <td>20.19082</td>\n",
       "      <td>-162.50028</td>\n",
       "      <td>-123.04788</td>\n",
       "      <td>-71.11772</td>\n",
       "      <td>-8.96605</td>\n",
       "      <td>-51.72176</td>\n",
       "      <td>30.53830</td>\n",
       "      <td>15.27979</td>\n",
       "      <td>-34.99486</td>\n",
       "      <td>...</td>\n",
       "      <td>-73.13628</td>\n",
       "      <td>18.76005</td>\n",
       "      <td>46.07843</td>\n",
       "      <td>-309.69087</td>\n",
       "      <td>-24.52842</td>\n",
       "      <td>-35.79334</td>\n",
       "      <td>-774.53143</td>\n",
       "      <td>3.34849</td>\n",
       "      <td>-194.68101</td>\n",
       "      <td>-41.23842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2007</td>\n",
       "      <td>25.10092</td>\n",
       "      <td>-189.85543</td>\n",
       "      <td>-28.69605</td>\n",
       "      <td>-34.42398</td>\n",
       "      <td>24.64007</td>\n",
       "      <td>-55.86989</td>\n",
       "      <td>63.91339</td>\n",
       "      <td>17.88235</td>\n",
       "      <td>-3.39713</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.70478</td>\n",
       "      <td>40.14964</td>\n",
       "      <td>95.55738</td>\n",
       "      <td>-36.47506</td>\n",
       "      <td>-8.63102</td>\n",
       "      <td>-34.57157</td>\n",
       "      <td>-13.63610</td>\n",
       "      <td>8.25615</td>\n",
       "      <td>108.42127</td>\n",
       "      <td>3.51335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0         1          2          3         4         5         6   \\\n",
       "0  2007  25.23214 -232.77465  -37.51542 -40.34335  56.11564 -55.94831   \n",
       "1  2007  27.96974 -166.08713  -11.19265 -28.07397 -56.10902 -35.47258   \n",
       "2  2007  24.75152  -97.45055  -40.15226 -43.39929 -57.25665 -33.93026   \n",
       "3  2007  20.19082 -162.50028 -123.04788 -71.11772  -8.96605 -51.72176   \n",
       "4  2007  25.10092 -189.85543  -28.69605 -34.42398  24.64007 -55.86989   \n",
       "\n",
       "         7         8         9   ...        81         82         83  \\\n",
       "0  43.06882  15.46278 -38.67370  ... -15.64058  257.69408  113.59740   \n",
       "1  23.35854   7.19973 -36.81179  ...  21.49227  289.05914  -34.75972   \n",
       "2  -1.95605   0.93121   7.76578  ...  -5.96584  573.94557   11.83355   \n",
       "3  30.53830  15.27979 -34.99486  ... -73.13628   18.76005   46.07843   \n",
       "4  63.91339  17.88235  -3.39713  ...  -3.70478   40.14964   95.55738   \n",
       "\n",
       "          84        85         86         87       88         89        90  \n",
       "0  -90.14988 -13.41911  -72.59105 -185.49959  1.16272  -73.13128  -6.89193  \n",
       "1  -19.38242   2.44006  -67.78591  -46.62749  0.38383   98.98315  13.14364  \n",
       "2 -107.81947  -3.42495 -141.79299 -150.79400  0.55715  148.71490  -2.41587  \n",
       "3 -309.69087 -24.52842  -35.79334 -774.53143  3.34849 -194.68101 -41.23842  \n",
       "4  -36.47506  -8.63102  -34.57157  -13.63610  8.25615  108.42127   3.51335  \n",
       "\n",
       "[5 rows x 91 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Read in the comma separated training data located at /data/<dataset>.csv using the pandas.read_csv() function\n",
    "# and print out the first few rows of the dataset using the .head() function\n",
    "# Make sure to specify header=None in the read_csv() call\n",
    "\n",
    "training_data_subset = pd.read_csv('/home/ubuntu/data/msd_training_data_split.csv', sep=\",\", header=None)\n",
    "training_data_subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_subset = training_data_subset.iloc[:, 0]\n",
    "y_train_subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_train_subset = training_data_subset.iloc[:, 1:]\n",
    "x_train_subset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess the test data located at /data/dataset_test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: split the test data into features and labels\n",
    "test_data_subset = pd.read_csv('/data/msd_test_data_split.csv', sep=\",\", header=None)\n",
    "y_test_subset = test_data_subset.iloc[:, 0]\n",
    "x_test_subset = test_data_subset.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model with the training data. Feel free to play with the hyperparameters. For example, you may want to adjust the `n_estimators` hyperparameter, which adjusts the number of trees in the ensemble. For a full list of hyperparameters, go here: https://xgboost.readthedocs.io/en/latest/parameter.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = xgb.XGBRegressor()\n",
    "# TODO: fit the model to the training data\n",
    "model.fit(x_train_subset, y_train_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get predictions and evaluate the model with the test data. Feel free to use different error functions. We suggest the sklearn mean_squared_error() or mean_absolute_error() functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(x_test_subset)\n",
    "np.sqrt(mean_squared_error(preds, y_test_subset))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
